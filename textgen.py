# -*- coding:utf-8 -*-
import time

# from langchain_community.embeddings import HuggingFaceBgeEmbeddings
# from langchain_community.vectorstores.chroma import Chroma

from app import prompt
from app.ai_generator import LocalLLMGenerator, QianWenGenerator
from app.data_factory import extract_and_save_as_json

from app.utils.document_splitter.text_splitter import RecursiveCharacterTextSplitter
import graphsignal
import asyncio

from app.database.leo_neo4j_graph import DatabaseConfig, Leo_Neo4jGraph

graphsignal.configure(api_key='f2ec8486fa256a498ef9272ad9981422', deployment='my-model-prod-v1')

from langchain_community.graphs.graph_document import GraphDocument
from langchain_community.graphs.graph_document import Node, Relationship

from langchain_core.documents import Document

from app.models import UserProfile
from app.models import CharacterProfile
import re  # å¯¼å…¥ re æ¨¡å—
from langchain_community.llms import Tongyi
# from app.utils.data_loader import DataLoader
import json
from app.core.prompts.tool_prompts import search_helper, search_graph_helper
from fastapi import FastAPI
from app.service.service import get_chat_history_service,get_diray_service


def split_text(documents, chunk_size, chunk_overlap):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    return text_splitter.split_documents(documents)


import databases

DATABASE_URL = "mysql+mysqlconnector://<username>:<password>@<host>/<dbname>"
database = databases.Database(DATABASE_URL)
# metadata = sqlalchemy.MetaData()


app = FastAPI()
# Base = declarative_base()

query = ""
data_config = DatabaseConfig("config.ini")
try:
    graphdb = Leo_Neo4jGraph(data_config.neo4j_uri, data_config.neo4j_username, data_config.neo4j_password)
except Exception as e:
    print(e)
#
# documents_env = DataLoader("game_env.csv").load()
# documents_env_dec = DataLoader("game_env_dec.txt").load()
#
# documents_env = split_text(documents_env, 50, 10)
# documents_env_dec = split_text(documents_env_dec, 50, 10)

# model_name = "thenlper/gte-small-zh"  # é˜¿é‡ŒTGE
# # model_name = "BAAI/bge-small-zh-v1.5" # æ¸…åBGE
# encode_kwargs = {'normalize_embeddings': True}
# embedding_model = HuggingFaceBgeEmbeddings(
#     model_name=model_name,
#     model_kwargs={'device': 'cpu'},
#     encode_kwargs=encode_kwargs
# )
# vectordb = Chroma.from_documents(documents=documents_env, embedding=embedding_model)
#
# files = ["æ—¥å¸¸é—®å€™.csv", "ä¼ ç»ŸèŠ‚æ—¥.csv", "äºŒåå››èŠ‚æ°”.csv", "ç¦ç”¨äººç‰©.txt"]
#
# for file in files:
#     documents = DataLoader(file).load()
#     vectordb.add_documents(documents)

intention_llm = LocalLLMGenerator()

topic_llm = LocalLLMGenerator()
# test = OpenAIGenerator()
generator = QianWenGenerator()
# generator = ChatGlmGenerator()

gpu_server_generator = LocalLLMGenerator()

from app.service.service import *

# å‡è®¾çš„ä¼šè¯ID
session_id = "123"

# è°ƒç”¨æœåŠ¡å±‚å‡½æ•°
user_profile, character_profile = get_user_and_character_profiles(session_id)
dialogue_manager = get_dialogue_manager_service(session_id)
# print(update_dialogue_summary_service(session_id, "æ¦‚è¦æµ‹è¯•"))
# print(get_dialogue_summary_service(session_id))
# print(update_dialogue_situation_service(session_id, "æƒ…å¢ƒæµ‹è¯•"))
# print(get_dialogue_situation_service(session_id))
# print(update_entity_summary_service(session_id, "å®ä½“æµ‹è¯•"))
# print(get_entity_summary_service(session_id))


# ä½¿ç”¨è·å–åˆ°çš„æ•°æ®
if user_profile and character_profile:
    print("User Name:", user_profile.name)
    print("Character Name:", character_profile.name)

from app.service.service import *

# extracted_triplets = [("ç”¨æˆ·", "æ— æ˜ç¡®éœ€æ±‚")]
default_dialogue_situation = """åœ¨ä¸€ä¸ªæ¸©é¦¨çš„å®¢å…å†…ï¼Œé˜³å…‰é€è¿‡çª—æˆ·æ´’ä¸‹ï¼Œå°†æ•´ä¸ªç©ºé—´æ¸²æŸ“æˆæ¸©æš–çš„è‰²è°ƒã€‚å®¢å…é‡Œæ‘†æ”¾ç€æŸ”è½¯çš„æ²™å‘å’Œè‰²å½©æ–‘æ–“çš„æŠ±æ•ï¼Œåˆ›é€ å‡ºä¸€ä¸ªæ”¾æ¾å’Œèˆ’é€‚çš„ç¯å¢ƒã€‚ä¸ä»…å¦‚æ­¤ï¼Œæˆ¿é—´ä¸­è¿˜å¸ƒæ»¡äº†æ¢¦å¹»èˆ¬çš„è£…é¥°ï¼šå°å–‡å­ã€å¤é“œè‰²è½åœ°ç¯ã€é­”æ³•å°çŒªé“¶è¡Œï¼Œä»¥åŠå……æ»¡ç«¥è¶£çš„å¤§ç™½å–µå’Œå°å…”å›¾æ¡ˆåœ°æ¯¯ã€‚è¿™ä¸ä»…æ˜¯ä¸€ä¸ªå®¢å…ï¼Œæ›´åƒæ˜¯ä¸€ä¸ªå……æ»¡æ•…äº‹å’Œæ¢¦æƒ³çš„å°ä¸–ç•Œã€‚
åœ¨è¿™æ¬¡å†’é™©çš„å¼€å§‹ï¼Œ{char}å’Œ{user}åœ¨å……æ»¡æ¢¦å¹»çš„å®¢å…ä¸­ç›¸é‡ã€‚{char}ï¼ŒåŸæ˜¯ä¸€ä¸ªç«¥è¯ä¸–ç•Œä¸­çš„å°é…è§’ï¼Œé€šè¿‡ç¥ç§˜åŠ›é‡è¿›å…¥äº†{user}æ‰€åœ¨çš„ä¸–ç•Œã€‚åœ¨è¿™ä¸ªå…¨æ–°çš„ç¯å¢ƒä¸­ï¼Œ{char}è¡¨ç°å‡ºå¥½å¥‡å’Œæ¿€åŠ¨ï¼Œè€Œ{user}åˆ™æ˜¾å¾—æœ‰äº›å›°æƒ‘ä½†ä¹Ÿä¹äºæ¥å—è¿™ä¸ªæ„å¤–çš„ä¼™ä¼´ã€‚ç»è¿‡ä¸€ç³»åˆ—çš„äº’åŠ¨å’Œæ¢ç´¢ï¼Œä»–ä»¬å»ºç«‹äº†å‹è°Šï¼Œå¹¶ä¸€èµ·åˆ¶ä½œé£Ÿç‰©ã€æ¢ç´¢ç§æ¤é—´ï¼Œå‘ç°äº†æ¼‚æµ®çš„éœ²ç ï¼Œå¹¶ç”¨å®ƒåˆ¶ä½œäº†ç¥å¥‡çš„é¦™é¦™æ±½æ°´ã€‚"""

impression = "[ç¤¼è²Œ][å‹å¥½]"

# prompt_test = prompt.prompt_test.format(char=character_profile.name, user=user_profile.name)

# ANSIè½¬ä¹‰åºåˆ—
ORANGE = '\033[33m'
GREEN = '\033[32m'
RESET = '\033[0m'


# dialogue_manager.situation = default_dialogue_situation.format(char=character_profile.name, user=user_profile.name)


# æ„å›¾è¯†åˆ«å›è°ƒ
def callback_intention(content, usage):
    # print(f"{ORANGE}ğŸ”·ğŸ”·ğŸ”·ç”Ÿæˆæ–‡æœ¬ğŸ”·ğŸ”·ğŸ”·\n{text}{RESET}")
    # global intention
    typewriter(content)
    dialogue_manager.intention = content

    # print(f"{GREEN}\nğŸ“>è¾…åŠ©æ„å›¾>>>>>{content}{RESET}")


# å‚è€ƒèµ„æ–™å›è°ƒ
def callback_rag_summary(content, usage):
    if content == "FALSE":
        print(f"{ORANGE}ğŸ”·ğŸ”·ğŸ”·å‚è€ƒèµ„æ–™ğŸ”·ğŸ”·ğŸ”·\n***æ²¡æœ‰åˆé€‚çš„å‚è€ƒèµ„æ–™ï¼Œéœ€æ›´åŠ æ³¨æ„å›ç­”æ—¶çš„äº‹å®ä¾æ®ï¼é¿å…å¹»è§‰ï¼***{RESET}")
    else:
        global reference
        reference = content
        print(f"{GREEN}\nğŸ“‘>èµ„æ–™å®ä½“>>>>>Entity Identification:\n{content}{RESET}")


async def callback_knowledge_graph(content):
    # global testText
    # testText = content
    full_content = await typewriter(content)
    # npcName= "çº¢å¿ƒçš‡å"
    # query = f"""
    # MATCH (n)-[r]->(m)
    # WHERE n.npcName = '{npcName}'
    # RETURN n, r, m
    # LIMIT 10
    # """
    document_source = Document(
        page_content="åŠ¨æ€æ¸¸æˆä¿¡æ¯",
        metadata={"author": "leozy", "date": "2024"}
    )
    # result = graphdb.query(query)

    # user = Node(id="å¤§å¤´", type="user", properties={"name": "å¤§å¤´"})
    # charactor = Node(id="å…”å½", type="charactor", properties={"name": "å…”å½"})
    # friendship = Relationship(source=user, target=charactor, type="FRIENDS_WITH", properties={"since": "2024"})
    # graph_doc = GraphDocument(nodes=[user, charactor], relationships=[friendship], source=document_source)

    graph_document = process_entities_and_relationships(full_content)
    graphdb.add_graph_documents([graph_document])
    print(f"{GREEN}\nğŸ“‘>å›¾è°±>>>>>:\n{full_content}{RESET}")


def clean_json_data(data: str) -> str:
    """
    æ¸…ç† JSON æ•°æ®å­—ç¬¦ä¸²ï¼Œç§»é™¤å¤šä½™çš„å­—ç¬¦ã€‚
    :param data: åŸå§‹æ•°æ®å­—ç¬¦ä¸²ã€‚
    :return: æ¸…ç†åçš„å­—ç¬¦ä¸²ã€‚
    """
    # ç§»é™¤å¯èƒ½çš„å¤šä½™å­—ç¬¦ï¼Œä¾‹å¦‚ï¼š```json å’Œ ```
    data = re.sub(r'^\s*```json\s*|\s*```\s*$', '', data, flags=re.MULTILINE)
    # å¤„ç†å…¶ä»–å¯èƒ½çš„æ ¼å¼é—®é¢˜ï¼ˆæ ¹æ®å®é™…æƒ…å†µæ·»åŠ ï¼‰
    # ...
    print(data)
    return data


def process_entities_and_relationships(data: str) -> GraphDocument:
    try:
        # æ¸…ç†æ•°æ®å¹¶è§£æ JSON
        clean_data = clean_json_data(data)
        data_dict = json.loads(clean_data)

        # æå–å®ä½“å’Œå…³ç³»
        entities_data = data_dict.get("å®ä½“", [])
        relationships_data = data_dict.get("å…³ç³»", [])

        # åˆ›å»ºèŠ‚ç‚¹å¯¹è±¡
        nodes = {entity['id']: Node(id=entity['id'], type=entity['type'], properties={"name": entity['name']})
                 for entity in entities_data}

        # åˆ›å»ºå…³ç³»å¯¹è±¡
        relationships = []
        for rel in relationships_data:
            source_node = nodes.get(rel['source_id'])
            target_node = nodes.get(rel['target_id'])
            if source_node and target_node:
                relationships.append(Relationship(source=source_node, target=target_node, type=rel['type']))

        # åˆ›å»ºæ–‡æ¡£æ¥æº
        document_source = Document(page_content="åŠ¨æ€æ¸¸æˆä¿¡æ¯", metadata={"author": "leozy", "date": "2024"})

        # åˆ›å»ºå¹¶è¿”å› GraphDocument å¯¹è±¡
        print("å›¾è°±æ„å»ºå®Œæˆ---------")
        return GraphDocument(nodes=list(nodes.values()), relationships=relationships, source=document_source)
    except json.JSONDecodeError as e:
        raise ValueError(f"è§£æ JSON æ—¶å‡ºé”™ï¼š{e}")


from langchain_core.callbacks.base import BaseCallbackHandler
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser




from colorama import Fore, Style


class ChatCallbackHandler(BaseCallbackHandler):
    def on_text(self, text, **kwargs):
        # ä¿®æ”¹å­—ä½“é¢œè‰²
        print(Fore.RED + text + Style.RESET_ALL)

    def on_llm_end(self, response, **kwargs):
        # è°ƒç”¨ä½ æƒ³è¦æ‰§è¡Œçš„å‡½æ•°
        # parser = LLMResultParser()

        print({"response": response})


async def update_entity(session_id,user_input):
    user_profile, character_profile = get_user_and_character_profiles(session_id)
    dialogue_manager = get_dialogue_manager_service(session_id)
    summary = get_summary_service(session_id)
    history = get_chat_history_service(session_id, 10, False)

    # å®ä½“è¯†åˆ«
    llm = Tongyi(model_name="qwen-max-1201", top_p=0.1, dashscope_api_key="sk-dc356b8ca42c41788717c007f49e134a")
    entity_template = prompt.DEFAULT_ENTITY_SUMMARIZATION_TEMPLATE
    entity_prompt = PromptTemplate(template=entity_template, input_variables=["history", "summary", "entity", "input"])
    callback_handler = ChatCallbackHandler()
    output_parser = StrOutputParser()
    entity_chain = LLMChain(llm=llm, prompt=entity_prompt, output_parser=output_parser)
    entity_input = {"history": history,
                    "summary": summary,
                    "entity": user_profile.name,
                    "input":user_input}
    entity_result = await entity_chain.ainvoke(entity_input, callbacks=[callback_handler])
    entity_text = entity_result["text"]

    update_entity_summary_service(session_id,entity_text)

    print(f'{GREEN}\nğŸ“>å®ä½“æ›´æ–°>>>>>{entity_text}{RESET}')

# è·å–å½“å¤©å¼€å§‹çš„æ—¶é—´
def get_start_of_day(dt):
    return datetime(year=dt.year, month=dt.month, day=dt.day)



async def update_summary(session_id):

    user_profile, character_profile = get_user_and_character_profiles(session_id)
    chat_summary = get_chat_summary(session_id)

    # è·å–åŒ…å«message_idçš„æœ€è¿‘10æ¡æ¶ˆæ¯
    history = get_chat_history_service(session_id, 10, include_ids=True)
    message_ids = [msg["message_id"] for msg in history]
    messages = [msg["content"] for msg in history]

    # format_history = format_messages_with_role(messages)

    # print(f'{GREEN}\nğŸ“>å¯¹è¯å†å²>>>>>{history}{RESET}')
    # å¯¹è¯æ¦‚è¦
    llm = Tongyi(model_name="qwen-max-1201", top_p=0.2, dashscope_api_key="sk-dc356b8ca42c41788717c007f49e134a")
    summary_template = prompt.DEFAULT_SUMMARIZER_TEMPLATE
    summary_prompts = PromptTemplate(template=summary_template,
                                     input_variables=["new_lines", "summary", "user", "char"])
    output_parser = StrOutputParser()
    summary_chain = LLMChain(llm=llm, prompt=summary_prompts, output_parser=output_parser)
    summary_input = {"new_lines":history,
                     # "summary": dialogue_manager.summary,
                     # "user": user_profile.name,
                     # "char": character_profile.name
                     }
    summary_result = await summary_chain.ainvoke(summary_input)
    summary_text = summary_result["text"]
    # update_dialogue_summary_service(session_id, summary_text)
    bind_summary_service(session_id, summary_text, message_ids)

    # print(f'{GREEN}\nğŸ“>å¯¹è¯æ¦‚è¦>>>>>{summary_text}{RESET}')


async def on_update_situation_complete():
    # è¿™é‡Œæ˜¯å›è°ƒå‡½æ•°ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å½“ update_situation() å®Œæˆæ—¶éœ€è¦æ‰§è¡Œçš„ä»£ç 
    print("Update situation completed")


async def update_situation(callback, session_id):
    user_profile, character_profile = get_user_and_character_profiles(session_id)
    dialogue_manager = get_dialogue_manager_service(session_id)
    # æƒ…å¢ƒæ¨¡æ‹Ÿ
    llm = Tongyi(model_name="qwen-max-1201", top_p=0.1, dashscope_api_key="sk-dc356b8ca42c41788717c007f49e134a")
    situation_template = prompt.AGENT_SITUATION
    situation_prompt = PromptTemplate(template=situation_template,
                                      input_variables=["dialogue_situation", "dialogue_excerpt", "user", "char"])
    situation_chain = LLMChain(llm=llm, prompt=situation_prompt, output_parser=StrOutputParser())
    situation_input = {"dialogue_situation": dialogue_manager.situation,
                       "dialogue_excerpt": dialogue_manager.chat_history,
                       "user": user_profile.name,
                       "char": character_profile.name}
    situation_result = await situation_chain.ainvoke(situation_input)
    situation_text = situation_result["text"]
    print(f'{GREEN}\nğŸ“>æƒ…å¢ƒæ¨¡æ‹Ÿ>>>>>{situation_text}{RESET}')
    await callback()
    update_dialogue_situation_service(session_id, situation_text)


async def update_emotion(session_id):
    # æƒ…ç»ª
    user_profile, character_profile = get_user_and_character_profiles(session_id)
    dialogue_manager = get_dialogue_manager_service(session_id)

    history = get_chat_history_service(session_id, 10, False)
    llm = Tongyi(model_name="qwen-max-1201", top_p=0.1, dashscope_api_key="sk-dc356b8ca42c41788717c007f49e134a")
    emotion_template = prompt.AGENT_EMOTION
    emotion_prompt = PromptTemplate(template=emotion_template,
                                    input_variables=["emotion", "dialogue_situation", "history", "char"])
    emotion_chain = LLMChain(llm=llm, prompt=emotion_prompt, output_parser=StrOutputParser())
    emotion_input = {"emotion": character_profile.emotional_state,
                     "history":history,
                     "char": character_profile.name}
    emotion_result = await emotion_chain.ainvoke(emotion_input)
    emotion_text = emotion_result["text"]
    # character_profile.emotional_state = emotion_text
    update_character_emotion_service(session_id, emotion_text)
    print(f'{GREEN}\nğŸ“>æƒ…ç»ªæ›´æ–°>>>>>{emotion_text}{RESET}')


from app.models.message import AiMessage, UserMessage,SystemMessage


async def callback_chat(content, session_id, query):
    task = ""
    head_idx = 0
    # print(f"{GREEN}\nğŸ“‘>Chain of thought>>>>>:{RESET}")
    # print(f"{GREEN}ğŸ®>GameData(sample)>>>>>:{character_profile}{RESET}")
    # for resp in content:
    #     paragraph = resp.output['text']
    #     # ç¡®ä¿æŒ‰å­—ç¬¦è€Œéå­—èŠ‚æ‰“å°
    #     for char in paragraph[head_idx:]:
    #         # æ‰“å°è“è‰²å­—ä½“
    #         print("\033[34m{}\033[0m".format(char), end='', flush=True)
    #         # æ¯ä¸ªå­—ç¬¦æ‰“å°åæš‚åœ0.1ç§’
    #         # time.sleep(0.01)
    #     head_idx = len(paragraph)
    #     # å¦‚æœæ®µè½ä»¥æ¢è¡Œç¬¦ç»“æŸï¼Œä¿ç•™è¯¥ä½ç½®
    #     if paragraph.endswith('\n'):
    #         head_idx -= 1
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSONéƒ¨åˆ†
    # å°†å­—èŠ‚å¯¹è±¡è§£ç ä¸ºå­—ç¬¦ä¸²
    decoded_text = content.decode('utf-8')
    search_pattern = '"finish_reason":"stop"'
    # print(f"{decoded_text}")
    if search_pattern in decoded_text:
        result = "åŒ¹é…æˆåŠŸï¼Œæµå¼ä¼ è¾“åœæ­¢ï¼š'finish_reason:stop'."
        # æå–JSONå­—ç¬¦ä¸²
        json_str = decoded_text.split('data:', 1)[1].strip()
        # è½¬æ¢ä¸ºJSONå¯¹è±¡
        try:
            data_json = json.loads(json_str)
            # print(data_json['output']['text'])
            ai_message = data_json['output']['text']
            # æŒ‰ç…§ "FINAL_ANSWER" æ‹†åˆ†
            content_parts = ai_message.split("FINAL_ANSWER")
            if len(content_parts) > 1:
                # å¦‚æœå­˜åœ¨ "TASK"ï¼ŒæŒ‰ "TASK" è¿›ä¸€æ­¥æ‹†åˆ†
                task_parts = content_parts[1].split("TASK", 1)
                # è¿‡æ»¤ ";" å’Œ ":"
                final_answer_content = re.sub(r'[;:]', '', task_parts[0].strip())
            else:
                data_json = json.loads(json_str)
                # print(data_json['output']['text'])
                ai_message = data_json['output']['text']
                final_answer_content = ai_message
            print(f"{GREEN}\nâ›“FINAL>>>>>>{final_answer_content}{RESET}")
            user_profile, character_profile = get_user_and_character_profiles(session_id)
            # messages = get_chat_history_service(session_id)
            # if messages is None:  # å¥½ä¹ æƒ¯å¥½ä¹ æƒ¯
            #     messages = []
            messages = []
            user_message = UserMessage(role=user_profile.name, message=query)
            ai_message = AiMessage(role=character_profile.name, message=final_answer_content)

            messages.append(user_message)
            messages.append(ai_message)

            total_messages  = update_chat_history_service(session_id, messages)
            # å¦‚æœæ¶ˆæ¯æ€»æ•°æ˜¯10çš„å€æ•°ï¼Œåˆ™ç”Ÿæˆæ¦‚è¦
            if total_messages % 10 == 0:
                # get_chat_history_service(session_id, 10)
                await update_summary(session_id)

            # update_dialogue_chat_history_service(session_id,f'{character_profile.name}:{final_answer_content}')

            #ä»»åŠ¡
            tasks = [
                update_emotion(session_id),
                update_entity(session_id,query),
            ]
            await asyncio.gather(*tasks)
            # åˆ›å»ºä¸€ä¸ªæ–°çš„ä»»åŠ¡æ¥è¿è¡Œ update_situationï¼Œä¼ é€’å›è°ƒå‡½æ•°
            # asyncio.create_task(update_situation(on_update_situation_complete, session_id))
        except json.JSONDecodeError:
            print("JSONè§£æé”™è¯¯")
            data_json = {}

        else:
            result = "åŒ¹é…å¤±è´¥ï¼Œæµå¼ä¼ è¾“ä¸­ã€‚"
    # print(decoded_text)
    # print(result)

    # chat_content = paragraph
    # parts = paragraph.split("FINAL_ANSWER")
    # if len(parts) > 1:
    #     answer_parts = parts[1].split("TASK")
    #     # if answer_parts:
    #     chat_content = f"{character_profile.name}{parts[1].strip()}"
    #
    #     impression_part = chat_content.split("\n")
    #     if len(impression_part) > 1:
    #         task = impression_part[1].strip()
    #         print(f"{GREEN}\nğŸ“>TASK>>>>>{task}{RESET}")
    #
    #         # cleaned_text = re.sub(r'[^a-zA-Z]', '', answer_parts[1].strip())
    # # print(f"{GREEN}\nâ›“FINAL>>>>>>{chat_content}{RESET}")
    # dialogue_manager.chat_history.append(f'{user_profile.name}ï¼š{query}')
    # dialogue_manager.chat_history.append(chat_content)
    # dialogue_manager.intent_history.append(chat_content)
    # if "è®°å¿†æ›´æ–°" in task:
    #     # æ¦‚è¦æç¤º
    #     # prompt_summary = prompt.DEFAULT_SUMMARIZER_TEMPLATE.format(new_lines=chat_history, summary=summary,
    #     #                                                            user=user_name, char=char_name)
    #     # å®ä½“è¯†åˆ«
    #     prompt_entity = prompt.DEFAULT_ENTITY_SUMMARIZATION_TEMPLATE.format(history=dialogue_manager.chat_history,
    #                                                                         summary=f"{dialogue_manager.user_name}:{dialogue_manager.entity_summary}",
    #                                                                         entity=f"{dialogue_manager.user_name}",
    #                                                                         input=dialogue_manager.chat_history)
    #     await generator.async_sync_call_streaming(prompt_entity, callback=callback_entity_summary)
    #     # await generator.async_sync_call_streaming(prompt_summary, callback=callback_summary)
    # if "æƒ…å¢ƒæ›´æ–°" in task:
    #     # æƒ…å¢ƒæ¨¡æ‹Ÿ
    #     prompt_simulation = prompt.AGENT_SITUATION.format(dialogue_situation=dialogue_manager.situation,
    #                                                        dialogue_excerpt=dialogue_manager.chat_history,
    #                                                        user=dialogue_manager.user_name,
    #                                                        char=dialogue_manager.char_name)
    #     await generator.async_sync_call_streaming(prompt_simulation, callback=callback_simulation)
    # if "æƒ…ç»ªæ›´æ–°" in task:
    #     # æƒ…ç»ª
    #     prompt_emotion = prompt.AGENT_EMOTION.format(emotion=character_profile.emotional_state,
    #                                                  dialogue_situation=dialogue_manager.situation,
    #                                                  history=dialogue_manager.chat_history,
    #                                                  char=character_profile.name)
    #     await generator.async_sync_call_streaming(prompt_emotion, callback=callback_emotion)


async def typewriter(content):
    head_idx = 0
    full_text = ""  # ç”¨äºç´¯ç§¯æ‰€æœ‰æ‰“å°çš„æ–‡æœ¬
    for resp in content:
        paragraph = resp.output['text']
        # ç¡®ä¿æŒ‰å­—ç¬¦è€Œéå­—èŠ‚æ‰“å°
        for char in paragraph[head_idx:]:
            # æ‰“å°è“è‰²å­—ä½“
            print("\033[34m{}\033[0m".format(char), end='', flush=True)
            full_text += char  # æ·»åŠ å­—ç¬¦åˆ°å®Œæ•´æ–‡æœ¬
            # æ¯ä¸ªå­—ç¬¦æ‰“å°åæš‚åœ0.1ç§’
            # time.sleep(0.01)
        head_idx = len(paragraph)
        # å¦‚æœæ®µè½ä»¥æ¢è¡Œç¬¦ç»“æŸï¼Œä¿ç•™è¯¥ä½ç½®
        if paragraph.endswith('\n'):
            head_idx -= 1

    return full_text


async def callback_simulation(content):
    dialogue_manager.situation = content
    # await typewriter(content)
    # print(f"{GREEN}\nğŸ“>æƒ…å¢ƒæ¨¡æ‹Ÿ>>>>>{content}{RESET}")


async def callback_analysis(content):
    await typewriter(content)
    # print(f"{GREEN}\nğŸ“>å¯¹è¯åˆ†æ>>>>>{content}{RESET}")


async def callback_emotion(content):
    # char_emotion = content
    char_info.emotional_state = await typewriter(content)

    char_info = f"[å…´è¶£:é˜…è¯»ç«¥è¯ä¹¦], [æ€§æ ¼:å†…å‘ï¼Œå®³ç¾], {char_info.emotional_state}ï¼Œ[ç”Ÿç†çŠ¶æ€:æ­£å¸¸],[ä½ç½®ï¼šå®¢å…]ï¼Œ[åŠ¨ä½œï¼šç«™ç«‹]"


async def callback_summary(content):
    # global summary
    # summary = content

    # entity_db.add_texts(content)
    # decoded_content = content.decode('utf-8')
    # await typewriter(decoded_content)
    # dialogue_manager.summary_history.append(decoded_content)
    print(f'{GREEN}\nğŸ“>å¯¹è¯æ¦‚è¦>>>>>decoded_content{RESET}')
    # print(f"{GREEN}\nğŸ“>å¯¹è¯æ¦‚è¦>>>>>{content}{RESET}")


async def callback_entity_summary(content):
    dialogue_manager.entity_summary = content
    print(f"{GREEN}\nğŸ“>å®ä½“æ›´æ–°>>>>>{dialogue_manager.entity_summary}{RESET}")
    await typewriter(content)
    # print(f"{GREEN}\nğŸ“>å®ä½“è¯†åˆ«>>>>>{entity_user_summary}{RESET}")


@graphsignal.trace_function
# å†³ç­–æ¨¡å‹
async def decision_agent(prompt_decision):
    await generator.async_sync_call_streaming(prompt_decision, callback=callback_chat)


#
# async def async_sync_call_streaming(prompt_simulation):
#     # è¿™é‡Œå‡è®¾ generator.sample_sync_call_streaming å¯ä»¥ç›´æ¥ä½œä¸ºå¼‚æ­¥è°ƒç”¨
#     # å¦‚æœä¸æ˜¯ï¼Œä½ å¯èƒ½éœ€è¦åœ¨è¿™ä¸ªå‡½æ•°ä¸­ä½¿ç”¨å…¶ä»–çš„å¼‚æ­¥é€”å¾„æ¥è°ƒç”¨å®ƒ
#     await generator.async_sync_call_streaming(prompt_simulation, callback=callback_simulation)


# print(f"{GREEN}\nğŸ“>å½“å‰æƒ…å¢ƒ>>>>>{dialogue_manager.situation}{RESET}")
# print(f"{GREEN}\nğŸ“>äº‹ä»¶>>>>><äº‹ä»¶>çŒªé³„å˜å‡ºäº†é‡‘å¸ï¼Œå“¥å“¥å’Œå…”å½å¾—åˆ°ä¸€äº›é‡‘å¸ï¼Œä½†çŒªé³„é™åˆ¶äº†æ•°é‡ã€‚{RESET}")

from langchain_community.llms.tongyi import generate_with_retry

# import spacy
# nlp = spacy.load('zh_core_web_sm')
# æ·»åŠ è‡ªå®šä¹‰è¯æ±‡
# nlp.tokenizer.pkuseg_update_user_dict(["å…”å½","å“¥å“¥"])
# æ‰§è¡Œä¸€äº›ç®€å•çš„NLPä»»åŠ¡
# doc = nlp("å§å®¤å¨æˆ¿ä¹”å¸ƒæ–¯")
# for ent in doc.ents:
#     # å®ä½“æ–‡æœ¬ï¼Œå¼€å§‹ä½ç½®ï¼Œç»“æŸä½ç½®ï¼Œå®ä½“æ ‡ç­¾
#     print(ent.text, ent.start_char, ent.end_char, ent.label_)
from pydantic import BaseModel
from typing import Optional

class GenerationRequest(BaseModel):
    data: str  # æ•°æ®æ¨¡å‹
    fullCOT: Optional[bool] = False
    user_location: Optional[str] = None  # ç”¨æˆ·ä½ç½®
    dialogue_situation: Optional[str] = None  # å¯¹è¯æƒ…å¢ƒ
    role_location: Optional[str] = None  # è§’è‰²ä½ç½®
    role_action: Optional[str] = None  # è§’è‰²åŠ¨ä½œ
    role_emotion: Optional[str] = None  # è§’è‰²æƒ…ç»ª
    role_physical_state: Optional[str] = None  # è§’è‰²ç”Ÿç†çŠ¶æ€
    sessionId: str  # sessionId

class UpdateMessageRequest(BaseModel):
    sessionId: str
    role: str
    message: str


class GetEmotionData(BaseModel):
    sessionId: str  # sessionId

class SessionData(BaseModel):
    sessionId: str  # sessionId

class TouchEventData(BaseModel):
    sessionId: str
    user_location: Optional[str] = None # ç”¨æˆ·ä½ç½®
    user_action: Optional[str] = None # ç”¨æˆ·åŠ¨ä½œ
    action_object: Optional[str] = None  # åŠ¨ä½œå¯¹è±¡
    object_description: Optional[str] = None  # å¯¹è±¡æè¿°
    object_feedback: Optional[str] = None  # å¯¹è±¡åé¦ˆ
    role_location: Optional[str] = None  # è§’è‰²ä½ç½®
    role_action: Optional[str] = None  # è§’è‰²åŠ¨ä½œ
    role_emotion: Optional[str] = None  # è§’è‰²æƒ…ç»ª
    role_physical_state: Optional[str] = None  # è§’è‰²ç”Ÿç†çŠ¶æ€
    anticipatory_reaction: Optional[str] = None  # é¢„æœŸååº”



class SituationData(BaseModel):
    sessionId: str  # sessionId


from fastapi.responses import StreamingResponse
import httpx
from sse_starlette.sse import EventSourceResponse
import requests
# @app.post("/stream-input")
# async def stream_input(request: Request):
#     # è¿™é‡Œæ˜¯å¤„ç†æ¥æ”¶åˆ°çš„æµå¼æ•°æ®çš„é€»è¾‘
#     # ä¾‹å¦‚ï¼Œå°†æ•°æ®å­˜å‚¨åœ¨é˜Ÿåˆ—ä¸­
#     pass
from fastapi.middleware.cors import CORSMiddleware

# è®¾ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æº

    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰æ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰å¤´
)

from fastapi import HTTPException

@app.post("/validate-session")
async def validate_session(session_data: SessionData):
    session_id = session_data.sessionId
    return validate_session_id_service(session_id)

    # if is_valid:
    #     return {"valid": True}
    # else:
    #     create_session_id_service(session_id)
    #     raise HTTPException(status_code=400, detail="Invalid session,Created a new session.")
@app.post("/fetch-emotion")
async def fetch_emotion(update_message_request: GetEmotionData):
    session_id = update_message_request.sessionId
    return get_character_emotion_service(session_id)



@app.post("/situation-data")
async def situation_data(situation_data: SituationData):
    session_id = situation_data.sessionId
    situation = get_dialogue_situation_service(session_id)
    return {"situation": situation}


from langchain_community.llms.chatglm import ChatGLM


from typing import List, Dict, Any, Optional

def format_messages_with_role(messages: Optional[List[Dict[str, Any]]]) -> List[str]:
    if messages is None:
        return []

    formatted_messages = []
    for item in messages:
        try:
            if isinstance(item, dict):
                content = item.get('content')
                if isinstance(content, list):
                    for message in content:
                        role = message.get('role', 'Unknown')
                        msg = message.get('message', '')
                        formatted_messages.append(f"{role}: {msg}")
                else:
                    role = item.get('role', 'Unknown')
                    msg = item.get('message', '')
                    formatted_messages.append(f"{role}: {msg}")
        except Exception as e:
            # Log error (consider using logging library in real applications)
            print(f"Error processing message: {e}")
            continue  # Optionally, handle or log the error

    return formatted_messages



@app.post("/touch-event")
async def add_system_event(touch_event_data: TouchEventData):
    try:
        session_id = touch_event_data.sessionId
        start_of_today = get_start_of_day(datetime.now())
        history = get_chat_history_service(session_id, 3, include_ids=False, time=start_of_today)
        user_profile, character_profile = get_user_and_character_profiles(session_id)
        chat_summary = get_summary_service(session_id)
        char_state = f"ä½ç½®ï¼š{touch_event_data.role_location}ï¼ŒåŠ¨ä½œï¼š{touch_event_data.role_action}ï¼Œæƒ…ç»ªï¼š{touch_event_data.role_emotion}ï¼Œç”Ÿç†çŠ¶æ€ï¼š{touch_event_data.role_physical_state}"
        event_info = f"{user_profile.name}çš„ä½ç½®ï¼š{touch_event_data.user_location}ï¼Œ{user_profile.name}çš„åŠ¨ä½œï¼š{touch_event_data.user_action}ï¼ŒåŠ¨ä½œå¯¹è±¡ï¼š{touch_event_data.action_object}ï¼Œå¯¹è±¡æè¿°ï¼š{touch_event_data.object_description}ï¼Œå¯¹è±¡åé¦ˆï¼š{touch_event_data.object_feedback}ï¼Œé¢„æœŸååº”ï¼š{touch_event_data.anticipatory_reaction}"
        llm = Tongyi(model_name="qwen-max-1201", top_p=0.85,temperature=1.5,repetition_penalty=2, dashscope_api_key="sk-dc356b8ca42c41788717c007f49e134a")
        template = prompt.TOUCH_EVENT
        format_prompt = PromptTemplate(template=template,
                                       input_variables=["lines_history", "char", "user", "event", "charactor_profile"])
        chain = LLMChain(llm=llm, prompt=format_prompt, output_parser=StrOutputParser())
        chain_input = {
            "lines_history": history,
            "char": character_profile.name,
            "user": user_profile.name,
            "char_state": char_state,
            "event_info": event_info,
            "summary":chat_summary,
        }
        print(f"äº‹ä»¶æç¤ºè¯:{chain_input}")
        result = await chain.ainvoke(chain_input)
        text = result["text"]

        # äº‹ä»¶åŠ å…¥åˆ°æ—¥å¿—
        messages = []
        prompt_message = SystemMessage(role="System", message=f"{character_profile.name}è¿›è¡Œäº†äº¤äº’ã€‚")
        new_message = SystemMessage(role="System", message=event_info)
        # char_message = AiMessage(role=character_profile.name, message=text)
        messages.append(prompt_message)
        messages.append(new_message)
        # messages.append(char_message)
        update_chat_history_service(session_id, messages)
    except Exception as e:
        print(f"Error processing touch event: {e}")
        text = f"å‡ºç°äº†ä¸€äº›é—®é¢˜ï¼Œæ— æ³•å¤„ç†æ‚¨çš„äº‹ä»¶:{e}"
    return {"content": text}

@app.post("/update-message")
async def update_chat_history(update_request: UpdateMessageRequest):
    sessionId = update_request.sessionId
    role = update_request.role
    message_content = update_request.message

    # messages = get_chat_history_service(sessionId)
    # if messages is None:
    #     messages = []
    messages = []
    new_message = SystemMessage(role=role, message=message_content)
    messages.append(new_message)

    update_chat_history_service(sessionId, messages)

    return {"status": "ok"}

@app.post("/fetch-chat-history")
async def fetch_chat_history(session_data: SessionData):
    sessionId = session_data.sessionId
    messages = get_chat_history_service(sessionId, 20)
    # formatted_messages_list = format_messages_with_role(messages)
    return {"messages": messages}

@app.post("/fetch-diary")
async def fetch_diary(session_data: SessionData):
    sessionId = session_data.sessionId
    diary = get_diray_service(sessionId)

    return {"diary": diary}


@app.post("/fetch-all-diaries")
async def fetch_all_diaries(session_data: SessionData):
    sessionId = session_data.sessionId
    diaries = get_diaries_all_service(sessionId)

    return {"diaries": diaries}

@app.post("/generate-diary")
async def generate_diary(session_data: SessionData):
    session_id = session_data.sessionId
    start_of_today = get_start_of_day(datetime.now())
    history = get_chat_history_service(session_id, 50, include_ids=False, time=start_of_today)
    user_profile, character_profile = get_user_and_character_profiles(session_id)

    llm = Tongyi(model_name="qwen-max-1201", top_p=0.25, dashscope_api_key="sk-dc356b8ca42c41788717c007f49e134a")
    template = prompt.DIARY
    format_prompt = PromptTemplate(template=template,
                                    input_variables=["lines_history", "char", "user"])
    chain = LLMChain(llm=llm, prompt=format_prompt, output_parser=StrOutputParser())
    chain_input = {
                     "lines_history": history,
                     "char": character_profile.name,
                     "user": user_profile.name}
    result = await chain.ainvoke(chain_input)
    text = result["text"]
    # åˆ†å‰²å­—ç¬¦ä¸²ä»¥æå–æ ‡é¢˜å’Œæ­£æ–‡
    parts = text.split("\nContent: ")
    title_part = parts[0].replace("Title: ", "")
    content_part = parts[1] if len(parts) > 1 else ""

    # æ„é€ ä¸€ä¸ªæ–°çš„å­—å…¸ï¼ŒåŒ…å«æ ‡é¢˜å’Œæ­£æ–‡
    diary_dict = {
        "title": title_part,
        "content": content_part
    }
    result = update_diary_service(session_id, diary_dict)

    #äº‹ä»¶åŠ å…¥åˆ°æ—¥å¿—
    messages = []
    prompt_message = SystemMessage(role="System", message=f"{character_profile.name}å†™äº†ä¸€ç¯‡æ—¥è®°")
    new_message = SystemMessage(role="System", message=diary_dict)
    messages.append(prompt_message)
    messages.append(new_message)
    update_chat_history_service(session_id, messages)

    return {"status": "ok", "diary": result}

from datetime import datetime
import os

# os.environ["OPENAI_API_KEY"] = "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"




# @app.post("/generate-openai")
# async def generate(request: GenerationRequest):
#     pr = request.data
#
#
#     llm = OpenAI(openai_api_key="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")
#
#     async_generator = llm.astream(input=pr, stream=True)
#
#     # å®šä¹‰ä¸€ä¸ªå¼‚æ­¥ç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºé€‚é…EventSourceResponseçš„è¦æ±‚
#     async def event_source_generator():
#         async for chunk in async_generator:
#             # æ ¹æ®EventSourceResponseçš„è¦æ±‚æ ¼å¼åŒ–æ¯ä¸ªå—
#
#             yield chunk
#
#     # åˆ›å»ºä¸€ä¸ªStreamingResponseå¯¹è±¡ï¼Œå°†å…¶è®¾ç½®ä¸ºå“åº”ä½“
#     return EventSourceResponse(event_source_generator())

@app.post("/generate")
async def generate(request: GenerationRequest):
    query = request.data
    sessionId = request.sessionId


    user_profile, character_profile = get_user_and_character_profiles(sessionId)
    dialogue_manager = get_dialogue_manager_service(sessionId)
    history = get_chat_history_service(sessionId,10)
    formatted_messages_list = format_messages_with_role(history)
    chat_summary = get_summary_service(sessionId)

    print(f"ç”¨æˆ·è¾“å…¥ï¼š{query}")
    # search_help_prompt = search_graph_helper.format(schema="", content=query)
    # intention_prompt = f"{prompt.INTENTION.format(chat_history=dialogue_manager.chat_history,input=query)}"
    # gpu_server_generator.generate_normal(intention_prompt, callback=callback_intention)

    # llm = Tongyi(model_name="qwen-max-1201", top_p=0.1, dashscope_api_key="sk-dc356b8ca42c41788717c007f49e134a")
    # params = {
    #     **{"model": llm.model_name},
    #     **{"top_p": llm.top_p},
    # }
    # completion = generate_with_retry(llm=llm, prompt=search_help_prompt, **params)
    # print(completion)

    # dialogue_manager.intention = completion["output"]["text"]
    # dialogue_manager.intent_history.append(f'é—®ï¼š{query}')
    # docs = vectordb.similarity_search_with_score(query)
    #
    # page_contents = []
    # for doc, score in docs:
    #     # å°†æ¯ä¸ªæ–‡æ¡£çš„å†…å®¹å’Œå®ƒçš„å¾—åˆ†æ·»åŠ åˆ°page_contentsåˆ—è¡¨
    #     if score < 0.4:
    #         page_contents.append(f"{doc.page_content} (ä½™å¼¦ç›¸ä¼¼åº¦: {score})")
    #
    # if len(page_contents):
    #     combined_contents = '\n'.join(page_contents)
    #     print(f"{ORANGE}ğŸ“‘>å‚è€ƒèµ„æ–™>>>>>\n{combined_contents}{RESET}")
    #     # reference = combined_contents
    #
    #     # # å‚è€ƒèµ„æ–™å®ä½“æ¦‚æ‹¬
    #     # rag_summary = prompt.AGENT_RAG_ENTITY.format(reference=combined_contents)  # æš‚æ—¶ä¸æ¦‚æ‹¬
    #     # gpu_server_generator.generate_normal(rag_summary, callback=callback_rag_summary)  # æš‚æ—¶ä¸æ¦‚æ‹¬
    #
    # else:
    #     combined_contents = "***æ²¡æœ‰åˆé€‚çš„å‚è€ƒèµ„æ–™ï¼Œéœ€æ›´åŠ æ³¨æ„å›ç­”æ—¶çš„äº‹å®ä¾æ®ï¼é¿å…å¹»è§‰ï¼***"
    # # å†³ç­–æ¨¡å‹
    # prompt_decision = prompt.AGENT_DECISION.format(user_profile=user_profile,
    #                                                dialogue_situation=dialogue_situation,
    #                                                extracted_triplets=dialogue_manager.extracted_triplets,
    #                                                chat_history=dialogue_manager.chat_history,
    #                                                user=user_profile.name, char=character_profile.name, input=query)
    # prompt_knowledge = prompt.KNOWLEDGE_GRAPH.format(text=prompt_test)
    # character_profile = ("[å…´è¶£:é˜…è¯»ç«¥è¯ä¹¦], [æ€§æ ¼:å†…å‘ï¼Œå®³ç¾], [æƒ…ç»ªçŠ¶æ€:ç”Ÿæ°”"
    #              "   ]ï¼Œ[ç”Ÿç†çŠ¶æ€:é¥¥é¥¿],[ä½ç½®ï¼šå®¢å…]ï¼Œ[åŠ¨ä½œï¼šç«™ç«‹]...")
    print(f"{GREEN}ğŸ®>GameData(sample)>>>>>:{character_profile}{RESET}")
    # print(f"{GREEN}ğŸ®>GameData(sample)>>>>>:{user_profile.name}{RESET}")
    # prompt_extract = prompt.EXTRACT.format(user=user_profile.name, user_profile=user_profile,char=character_profile.name, character_profile=character_profile,
    #                                                 input=query, dialogue_situation=dialogue_manager.situation,
    #                                                 user_entity=dialogue_manager.entity_summary,
    #                                                 reference="None",
    #                                                 lines_history=formatted_messages_list,
    #                                                 summary_history=chat_summary),
    # print(prompt_extract)
    # è·å–å½“å‰æ—¥æœŸå’Œæ—¶é—´
    now = f"Current Time:{datetime.now()}"
    user_profile_str =f"name:{user_profile.name},interests:{user_profile.interests},personality:{user_profile.personality},emotional_state:{user_profile.emotional_state},physical_state:{user_profile.physical_state},location:{request.user_location},action:{user_profile.action}"
    character_profile_str = f"name:{character_profile.name},emotional_state:{character_profile.emotional_state},physical_state:{request.role_physical_state},location:{request.role_location},action:{request.role_action}"
    prompt_game = prompt.AGENT_ROLE_TEST.format(user=user_profile.name, user_profile=user_profile_str,
                                                char=character_profile.name, character_profile=character_profile_str,
                                                input=query, dialogue_situation=request.dialogue_situation,
                                                user_entity=dialogue_manager.entity_summary,
                                                reference="None",
                                                lines_history=formatted_messages_list,
                                                summary_history=chat_summary,
                                                current_time=now),
    prompt_short = prompt.SHORT_ROLE.format(user=user_profile.name, user_profile=user_profile_str,
                                                char=character_profile.name, character_profile=character_profile_str,
                                                input=query,dialogue_situation=request.dialogue_situation,
                                                user_entity=dialogue_manager.entity_summary,
                                                reference="None",
                                                lines_history=formatted_messages_list,
                                                summary_history=chat_summary,
                                                current_time=now),
    print(character_profile_str)
    # print(prompt_game)
    # print(prompt_short)
    if request.fullCOT:
        finale_prompt = prompt_game
    else:
        finale_prompt = prompt_short

    print("æƒ…æ™¯ï¼š",request.dialogue_situation)
    print("è§’è‰²ä½ç½®ï¼š",request.role_location)
    print("è§’è‰²åŠ¨ä½œï¼š",request.role_action)
    print("å®æ—¶è§’è‰²æƒ…ç»ªï¼š",character_profile.emotional_state)
    print("è§’è‰²ç”Ÿç†çŠ¶æ€ï¼š",request.role_physical_state)
    print("å¯¹è¯æ¦‚è¦",chat_summary)
    print("å®ä½“ï¼š",dialogue_manager.entity_summary)

    # await update_summary(sessionId)
    await update_entity(sessionId, query)

    return EventSourceResponse(
        generator.async_sync_call_streaming(finale_prompt, callback=callback_chat, session_id=sessionId, query=query))
